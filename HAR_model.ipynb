{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "<h4> Dataset Description</h4>\n",
    "\n",
    "The dataset used in this project contains tri-axial accelerometer readings recorded from a smartphone during different activities. Each reading includes:\n",
    "- **X, Y, and Z coordinates**: Representing the acceleration in each of the three dimensions.\n",
    "- **Timestamp and UTC time**: Indicating when the data was recorded.\n",
    "\n",
    "The goal of this project is to classify these accelerometer readings into various activities based on the patterns observed in the data. The challenge lies in handling the class imbalance and extracting meaningful features from the raw accelerometer data to build an effective classification model.\n",
    "\n",
    "<h4>Project Objectives and Key Steps</h4>\n",
    "\n",
    "The primary objective is to develop a machine learning model capable of accurately predicting the activity label from accelerometer data. To achieve this, the project involves the following key steps:\n",
    "1. **Data Preprocessing**: Cleaning and organizing the data to ensure quality and consistency.\n",
    "2. **Feature Extraction**: Using techniques like Fourier Transform to derive features that capture the underlying patterns in the data.\n",
    "3. **Model Training and Evaluation**: Selecting appropriate machine learning algorithms, tuning their hyperparameters, and evaluating their performance using metrics such as accuracy, precision, recall, and F1 score.\n",
    "4. **Handling Imbalanced Data**: Addressing the imbalance in activity classes to ensure the model performs well across all categories.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "<h4>Data Preprocessing</h4>\n",
    "\n",
    "- Checked data for missing or corrupted values in the dataset.\n",
    "- Checked class balance.\n",
    "- Checked for inclomplete sets of measurements.\n",
    "- Enriched data with acceleration magnitude.\n",
    "- Addressed `type` inconsistencies in the timestamp reccords.\n",
    "\n",
    "<h4>Feature Extraction</h4>\n",
    "\n",
    "- Applied the Fourier Transform to the accelerometer data to convert time-domain signals into frequency-domain features.\n",
    "   - Extracted median UTC time and relevant frequency components for each axis (X, Y, Z, and M).\n",
    "\n",
    "<h4>Modeling Approach</h4>\n",
    "\n",
    "0. **Class Imbalance Handling**:\n",
    "   - Calculated class weights to account for imbalanced activity classes, which were applied during model training and selection to prevent bias towards the majority class.\n",
    "   - Used techniques like Stratified K-Fold cross-validation to maintain the class distribution across training and validation splits.\n",
    "\n",
    "1. **Model Selection**:\n",
    "   - Evaluated multiple traditional machine learning models including Random Forest, Decision Tree, K-Nearest Neighbors, Logistic Regression, and Support Vector Machine.\n",
    "   - Used a combination of accuracy, precision, recall, and F1 score to select the best model.\n",
    "   - Chose K-Nearest Neighbors (KNN) based on a balanced trade-off in performance metrics.\n",
    "\n",
    "2. **Hyperparameter Tuning**:\n",
    "   - Employed Grid Search with cross-validation to find the optimal hyperparameters for the KNN model.\n",
    "   - Tuned the number of neighbors (`n_neighbors`), weight function (`weights`), and distance metric (`metric`).\n",
    "\n",
    "3. **Pipeline and Evaluation**:\n",
    "   - Implemented a pipeline to standardize the data and apply the KNN classifier.\n",
    "   - Evaluated the model using cross-validation and then assessed its performance on the test set using the F1 score as the primary metric.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "* Imports needed libraries and functions.\n",
    "* Starts the timer to track the notebook's total runing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.fft import fft\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track total notebook's runtime.\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "* Load tri-axial accelerometer train and test files.\n",
    "* Check loaded datasets for data quality and potential issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data from `.csv` files stored locally in the project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_time_series.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "\n",
    "test_data = pd.read_csv('test_time_series.csv')\n",
    "test_labels = pd.read_csv('test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previewing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>UTC time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20586</td>\n",
       "      <td>1565109930787</td>\n",
       "      <td>2019-08-06T16:45:30.787</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.934860</td>\n",
       "      <td>-0.069046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20587</td>\n",
       "      <td>1565109930887</td>\n",
       "      <td>2019-08-06T16:45:30.887</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-0.066467</td>\n",
       "      <td>-1.015442</td>\n",
       "      <td>0.089554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      timestamp                 UTC time accuracy         x  \\\n",
       "0       20586  1565109930787  2019-08-06T16:45:30.787  unknown -0.006485   \n",
       "1       20587  1565109930887  2019-08-06T16:45:30.887  unknown -0.066467   \n",
       "\n",
       "          y         z  \n",
       "0 -0.934860 -0.069046  \n",
       "1 -1.015442  0.089554  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>UTC time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20589</td>\n",
       "      <td>1565109931087</td>\n",
       "      <td>2019-08-06T16:45:31.087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20599</td>\n",
       "      <td>1565109932090</td>\n",
       "      <td>2019-08-06T16:45:32.090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      timestamp                 UTC time  label\n",
       "0       20589  1565109931087  2019-08-06T16:45:31.087      1\n",
       "1       20599  1565109932090  2019-08-06T16:45:32.090      1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>UTC time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24330</td>\n",
       "      <td>1565110306139</td>\n",
       "      <td>2019-08-06T16:51:46.139</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>-1.504456</td>\n",
       "      <td>0.157623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24331</td>\n",
       "      <td>1565110306239</td>\n",
       "      <td>2019-08-06T16:51:46.239</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.409164</td>\n",
       "      <td>-1.038544</td>\n",
       "      <td>0.030975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      timestamp                 UTC time accuracy         x  \\\n",
       "0       24330  1565110306139  2019-08-06T16:51:46.139  unknown  0.034286   \n",
       "1       24331  1565110306239  2019-08-06T16:51:46.239  unknown  0.409164   \n",
       "\n",
       "          y         z  \n",
       "0 -1.504456  0.157623  \n",
       "1 -1.038544  0.030975  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>UTC time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24339</td>\n",
       "      <td>1565110307041</td>\n",
       "      <td>2019-08-06T16:51:47.041</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24349</td>\n",
       "      <td>1565110308043</td>\n",
       "      <td>2019-08-06T16:51:48.043</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      timestamp                 UTC time  label\n",
       "0       24339  1565110307041  2019-08-06T16:51:47.041    NaN\n",
       "1       24349  1565110308043  2019-08-06T16:51:48.043    NaN"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview datasets' shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data's shape: (3744, 7)\n",
      "Train label's shape: (375, 4)\n",
      "Test data's shape: (1250, 7)\n",
      "Test label's shape: (125, 4)\n"
     ]
    }
   ],
   "source": [
    "shapes = f'Train data\\'s shape: {train_data.shape}\\nTrain label\\'s shape: {train_labels.shape}\\nTest data\\'s shape: {test_data.shape}\\nTest label\\'s shape: {test_labels.shape}'\n",
    "print(shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Empty DataFrame\n",
       " Columns: [Unnamed: 0, timestamp, UTC time, accuracy, x, y, z]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [Unnamed: 0, timestamp, UTC time, label]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [Unnamed: 0, timestamp, UTC time, accuracy, x, y, z]\n",
       " Index: [])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_nulls(df):\n",
    "    null_rows = df.isnull().any(axis=1)\n",
    "    return df[null_rows]\n",
    "\n",
    "check_nulls(train_data), check_nulls(train_labels), check_nulls(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for label balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "1     27\n",
       "2    213\n",
       "4     47\n",
       "3     88"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(Counter(train_labels['label']), orient='index', columns=['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 4 extra samples in the end of the training dataset which did not encompassed a full 10 sample measurement. Analogously, the train labels contained one \"extra\" label, matching those 4 measurements.\n",
    "\n",
    "As such a cleaning is performed on this \"incomplete\" data from the train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3740, 7), (374, 4))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data[:-4]\n",
    "train_labels = train_labels[:-1]\n",
    "\n",
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the magnitude of each acceleration vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude(df):\n",
    "    return np.sqrt(df.x**2 + df.y**2 + df.z**2)\n",
    "\n",
    "train_data['m'] = magnitude(train_data)\n",
    "test_data['m'] = magnitude(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking on timestamp columns' data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origital datatype of UTC time: <class 'str'>\n",
      "Origital datatype of UTC time: <class 'str'>\n",
      "Origital datatype of UTC time: <class 'str'>\n",
      "Origital datatype of UTC time: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('Origital datatype of UTC time:', type(train_data['UTC time'].iloc[1]))\n",
    "print('Origital datatype of UTC time:', type(train_labels['UTC time'].iloc[1]))\n",
    "print('Origital datatype of UTC time:', type(test_data['UTC time'].iloc[1]))\n",
    "print('Origital datatype of UTC time:', type(test_labels['UTC time'].iloc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert timestap data to time type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origital datatype of UTC time: <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Origital datatype of UTC time: <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Origital datatype of UTC time: <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Origital datatype of UTC time: <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "train_data['UTC time'] =  pd.to_datetime(train_data['UTC time'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "train_labels['UTC time'] =  pd.to_datetime(train_labels['UTC time'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "test_data['UTC time'] =  pd.to_datetime(test_data['UTC time'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "test_labels['UTC time'] =  pd.to_datetime(test_labels['UTC time'], format='%Y-%m-%dT%H:%M:%S.%f')\n",
    "\n",
    "print('Origital datatype of UTC time:', type(train_data['UTC time'].iloc[1]))\n",
    "print('Origital datatype of UTC time:', type(train_labels['UTC time'].iloc[1]))\n",
    "print('Origital datatype of UTC time:', type(test_data['UTC time'].iloc[1]))\n",
    "print('Origital datatype of UTC time:', type(test_labels['UTC time'].iloc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "* Extract relevant features from the raw accelerometer data.\n",
    "\n",
    "Given that the problem exhibits periodic and oscillatory behavior in its core, frequency domain information might be more informative for this task. Therefore, the features will be approached  with a Fourier Transform, considering a windowing technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to extract tri-axial accelerometer features, resorting to a sliding window approach to apply a fourrier transform over each sample data window.\n",
    "def extract_features(data, window_size=10, sampling_rate=10):\n",
    "    \"\"\"\n",
    "    Extract features from tri-axial accelerometer data within sliding windows using Fourier Transform.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame containing accelerometer data with columns 'x', 'y', 'z'\n",
    "    - window_size: Size of the sliding window\n",
    "    - sampling_rate: Sampling rate of the accelerometer data in Hz\n",
    "    \n",
    "    Returns:\n",
    "    - features: DataFrame containing extracted features with fixed frequency components\n",
    "    \"\"\"\n",
    "\n",
    "    features = []\n",
    "\n",
    "    frequencies = np.fft.fftfreq(window_size, d=1/sampling_rate)[:window_size//2]\n",
    "\n",
    "    for i in range(0, len(data) - window_size + 1, window_size):\n",
    "        \n",
    "        window_data = data.iloc[i:i+window_size]\n",
    "        \n",
    "        # Calculate median UTC time for the window\n",
    "        utc_time = window_data['UTC time'].median()\n",
    "        \n",
    "        # Apply Fourier Transform to each axis and take only the relevant frequency components (e.g., first half, excluding Nyquist frequency)\n",
    "        fft_x = np.abs(fft(window_data['x'].values))[:window_size//2]\n",
    "        fft_y = np.abs(fft(window_data['y'].values))[:window_size//2]\n",
    "        fft_z = np.abs(fft(window_data['z'].values))[:window_size//2]\n",
    "        fft_m = np.abs(fft(window_data['m'].values))[:window_size//2]\n",
    "        \n",
    "        # Concatenate the features\n",
    "        features.append(np.concatenate([[utc_time], fft_x, fft_y, fft_z, fft_m]))\n",
    "\n",
    "    feature_df = pd.DataFrame(features)\n",
    "    \n",
    "    # Include frequency labels in column names\n",
    "    frequency_labels = [f'freq_{freq:.2f}' for freq in frequencies]\n",
    "    feature_columns = (\n",
    "        ['UTC time'] +\n",
    "        [f'x_{label}' for label in frequency_labels] +\n",
    "        [f'y_{label}' for label in frequency_labels] +\n",
    "        [f'z_{label}' for label in frequency_labels] +\n",
    "        [f'm_{label}' for label in frequency_labels]\n",
    "    )\n",
    "    feature_df.columns = feature_columns\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating sample frequency of each window for better accuracy when applying Fourier transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: \n",
      "Average time per sample - 0.10 seconds\n",
      "Frequency per sample - 9.98 Hz\n",
      "\n",
      "Test data: \n",
      "Average time per sample - 0.10 seconds\n",
      "Frequency per sample - 9.98 Hz\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean time difference between consecutive 'UTC time' entries in the train_data DataFrame.\n",
    "# This is essentially computing the average time interval between each sample in the training data.\n",
    "T_train_data = np.mean([\n",
    "    train_data['UTC time'].iloc[i+1] - train_data['UTC time'].iloc[i]  # Difference between consecutive 'UTC time' values\n",
    "    for i in range(len(train_data['UTC time']) - 1)  # Iterate over the range up to the second-to-last index\n",
    "])\n",
    "\n",
    "# Calculate the overall sampling frequency (rate) of the training data.\n",
    "# This is computed as the total number of samples divided by the total time span of the dataset in seconds.\n",
    "f_train_data = len(train_data['UTC time']) / (  # Total number of samples\n",
    "    train_data['UTC time'].iloc[-1] - train_data['UTC time'].iloc[0]  # Total duration between the first and last 'UTC time'\n",
    ").total_seconds()  # Convert the total duration from a timedelta object to seconds\n",
    "\n",
    "# Repeating the process for test data.\n",
    "T_test_data = np.mean([test_data['UTC time'].iloc[i+1]-test_data['UTC time'].iloc[i] for i in range(len(test_data['UTC time'])-1)])\n",
    "f_test_data = len(test_data['UTC time'])/(test_data['UTC time'].iloc[-1]-test_data['UTC time'].iloc[0]).total_seconds()\n",
    "\n",
    "print('Train data: \\nAverage time per sample - {:.2f} seconds\\nFrequency per sample - {:.2f} Hz'.\\\n",
    "      format(T_train_data.total_seconds(), f_train_data))\n",
    "\n",
    "print('\\nTest data: \\nAverage time per sample - {:.2f} seconds\\nFrequency per sample - {:.2f} Hz'.\\\n",
    "      format(T_test_data.total_seconds(), f_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Fourier Transform to train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(train_data, 10, f_train_data)\n",
    "test_features = extract_features(test_data, 10, f_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((374, 21), (374, 4))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTC time</th>\n",
       "      <th>x_freq_0.00</th>\n",
       "      <th>x_freq_1.00</th>\n",
       "      <th>x_freq_2.00</th>\n",
       "      <th>x_freq_2.99</th>\n",
       "      <th>x_freq_3.99</th>\n",
       "      <th>y_freq_0.00</th>\n",
       "      <th>y_freq_1.00</th>\n",
       "      <th>y_freq_2.00</th>\n",
       "      <th>y_freq_2.99</th>\n",
       "      <th>...</th>\n",
       "      <th>z_freq_0.00</th>\n",
       "      <th>z_freq_1.00</th>\n",
       "      <th>z_freq_2.00</th>\n",
       "      <th>z_freq_2.99</th>\n",
       "      <th>z_freq_3.99</th>\n",
       "      <th>m_freq_0.00</th>\n",
       "      <th>m_freq_1.00</th>\n",
       "      <th>m_freq_2.00</th>\n",
       "      <th>m_freq_2.99</th>\n",
       "      <th>m_freq_3.99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-06 16:45:31.238000128</td>\n",
       "      <td>0.115494</td>\n",
       "      <td>0.213512</td>\n",
       "      <td>0.125321</td>\n",
       "      <td>0.270987</td>\n",
       "      <td>0.208459</td>\n",
       "      <td>9.829315</td>\n",
       "      <td>0.131838</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.152028</td>\n",
       "      <td>...</td>\n",
       "      <td>1.637115</td>\n",
       "      <td>0.535512</td>\n",
       "      <td>0.386162</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.179750</td>\n",
       "      <td>10.046286</td>\n",
       "      <td>0.111909</td>\n",
       "      <td>0.256019</td>\n",
       "      <td>0.149530</td>\n",
       "      <td>0.032842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-06 16:45:32.240000000</td>\n",
       "      <td>0.189102</td>\n",
       "      <td>0.424405</td>\n",
       "      <td>0.239227</td>\n",
       "      <td>0.152204</td>\n",
       "      <td>0.179354</td>\n",
       "      <td>9.860931</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>0.201607</td>\n",
       "      <td>0.411713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252670</td>\n",
       "      <td>0.611313</td>\n",
       "      <td>0.339826</td>\n",
       "      <td>0.190252</td>\n",
       "      <td>0.266903</td>\n",
       "      <td>9.961635</td>\n",
       "      <td>0.054050</td>\n",
       "      <td>0.193307</td>\n",
       "      <td>0.386611</td>\n",
       "      <td>0.373026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-06 16:45:33.241999872</td>\n",
       "      <td>0.645355</td>\n",
       "      <td>0.403384</td>\n",
       "      <td>0.056071</td>\n",
       "      <td>0.192648</td>\n",
       "      <td>0.133450</td>\n",
       "      <td>10.186569</td>\n",
       "      <td>0.087794</td>\n",
       "      <td>0.051352</td>\n",
       "      <td>0.126917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>0.286381</td>\n",
       "      <td>0.355345</td>\n",
       "      <td>0.248514</td>\n",
       "      <td>0.166124</td>\n",
       "      <td>10.259016</td>\n",
       "      <td>0.079909</td>\n",
       "      <td>0.075065</td>\n",
       "      <td>0.137016</td>\n",
       "      <td>0.127771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-06 16:45:34.244499968</td>\n",
       "      <td>0.070953</td>\n",
       "      <td>0.307256</td>\n",
       "      <td>0.320381</td>\n",
       "      <td>0.449271</td>\n",
       "      <td>0.115143</td>\n",
       "      <td>9.840561</td>\n",
       "      <td>0.273144</td>\n",
       "      <td>0.274306</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.552246</td>\n",
       "      <td>0.368782</td>\n",
       "      <td>0.172103</td>\n",
       "      <td>0.170834</td>\n",
       "      <td>0.268370</td>\n",
       "      <td>10.027267</td>\n",
       "      <td>0.272663</td>\n",
       "      <td>0.250511</td>\n",
       "      <td>0.327138</td>\n",
       "      <td>0.435102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-06 16:45:35.247000064</td>\n",
       "      <td>0.557709</td>\n",
       "      <td>0.099768</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>0.063887</td>\n",
       "      <td>10.031647</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526489</td>\n",
       "      <td>0.201086</td>\n",
       "      <td>0.060130</td>\n",
       "      <td>0.115041</td>\n",
       "      <td>0.082050</td>\n",
       "      <td>10.070970</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.013317</td>\n",
       "      <td>0.046099</td>\n",
       "      <td>0.006538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       UTC time  x_freq_0.00  x_freq_1.00  x_freq_2.00  \\\n",
       "0 2019-08-06 16:45:31.238000128     0.115494     0.213512     0.125321   \n",
       "1 2019-08-06 16:45:32.240000000     0.189102     0.424405     0.239227   \n",
       "2 2019-08-06 16:45:33.241999872     0.645355     0.403384     0.056071   \n",
       "3 2019-08-06 16:45:34.244499968     0.070953     0.307256     0.320381   \n",
       "4 2019-08-06 16:45:35.247000064     0.557709     0.099768     0.061064   \n",
       "\n",
       "   x_freq_2.99  x_freq_3.99  y_freq_0.00  y_freq_1.00  y_freq_2.00  \\\n",
       "0     0.270987     0.208459     9.829315     0.131838     0.229700   \n",
       "1     0.152204     0.179354     9.860931     0.099776     0.201607   \n",
       "2     0.192648     0.133450    10.186569     0.087794     0.051352   \n",
       "3     0.449271     0.115143     9.840561     0.273144     0.274306   \n",
       "4     0.043690     0.063887    10.031647     0.013636     0.014963   \n",
       "\n",
       "   y_freq_2.99  ...  z_freq_0.00  z_freq_1.00  z_freq_2.00  z_freq_2.99  \\\n",
       "0     0.152028  ...     1.637115     0.535512     0.386162     0.394200   \n",
       "1     0.411713  ...     0.252670     0.611313     0.339826     0.190252   \n",
       "2     0.126917  ...     0.004623     0.286381     0.355345     0.248514   \n",
       "3     0.317647  ...     1.552246     0.368782     0.172103     0.170834   \n",
       "4     0.047105  ...     0.526489     0.201086     0.060130     0.115041   \n",
       "\n",
       "   z_freq_3.99  m_freq_0.00  m_freq_1.00  m_freq_2.00  m_freq_2.99  \\\n",
       "0     0.179750    10.046286     0.111909     0.256019     0.149530   \n",
       "1     0.266903     9.961635     0.054050     0.193307     0.386611   \n",
       "2     0.166124    10.259016     0.079909     0.075065     0.137016   \n",
       "3     0.268370    10.027267     0.272663     0.250511     0.327138   \n",
       "4     0.082050    10.070970     0.026841     0.013317     0.046099   \n",
       "\n",
       "   m_freq_3.99  \n",
       "0     0.032842  \n",
       "1     0.373026  \n",
       "2     0.127771  \n",
       "3     0.435102  \n",
       "4     0.006538  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure that labels are assigned to the right features, by merging data on UTC time information. [^1] [^2]\n",
    "\n",
    "[^1]: Both train data and labels dataframes were in the same order, however this approach felt more rigorous.\n",
    "\n",
    "[^2]: By eyeballing the uploaded data it's easy to notice that each label is \"given\", about midway of the measured data. This way by mergin with the median UTC time of each window, I can be sure to have the labels on the right place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTC time</th>\n",
       "      <th>x_freq_0.00</th>\n",
       "      <th>x_freq_1.00</th>\n",
       "      <th>x_freq_2.00</th>\n",
       "      <th>x_freq_2.99</th>\n",
       "      <th>x_freq_3.99</th>\n",
       "      <th>y_freq_0.00</th>\n",
       "      <th>y_freq_1.00</th>\n",
       "      <th>y_freq_2.00</th>\n",
       "      <th>y_freq_2.99</th>\n",
       "      <th>...</th>\n",
       "      <th>z_freq_1.00</th>\n",
       "      <th>z_freq_2.00</th>\n",
       "      <th>z_freq_2.99</th>\n",
       "      <th>z_freq_3.99</th>\n",
       "      <th>m_freq_0.00</th>\n",
       "      <th>m_freq_1.00</th>\n",
       "      <th>m_freq_2.00</th>\n",
       "      <th>m_freq_2.99</th>\n",
       "      <th>m_freq_3.99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-06 16:45:31.238000128</td>\n",
       "      <td>0.115494</td>\n",
       "      <td>0.213512</td>\n",
       "      <td>0.125321</td>\n",
       "      <td>0.270987</td>\n",
       "      <td>0.208459</td>\n",
       "      <td>9.829315</td>\n",
       "      <td>0.131838</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.152028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535512</td>\n",
       "      <td>0.386162</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.179750</td>\n",
       "      <td>10.046286</td>\n",
       "      <td>0.111909</td>\n",
       "      <td>0.256019</td>\n",
       "      <td>0.149530</td>\n",
       "      <td>0.032842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-06 16:45:32.240000000</td>\n",
       "      <td>0.189102</td>\n",
       "      <td>0.424405</td>\n",
       "      <td>0.239227</td>\n",
       "      <td>0.152204</td>\n",
       "      <td>0.179354</td>\n",
       "      <td>9.860931</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>0.201607</td>\n",
       "      <td>0.411713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611313</td>\n",
       "      <td>0.339826</td>\n",
       "      <td>0.190252</td>\n",
       "      <td>0.266903</td>\n",
       "      <td>9.961635</td>\n",
       "      <td>0.054050</td>\n",
       "      <td>0.193307</td>\n",
       "      <td>0.386611</td>\n",
       "      <td>0.373026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-06 16:45:33.241999872</td>\n",
       "      <td>0.645355</td>\n",
       "      <td>0.403384</td>\n",
       "      <td>0.056071</td>\n",
       "      <td>0.192648</td>\n",
       "      <td>0.133450</td>\n",
       "      <td>10.186569</td>\n",
       "      <td>0.087794</td>\n",
       "      <td>0.051352</td>\n",
       "      <td>0.126917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286381</td>\n",
       "      <td>0.355345</td>\n",
       "      <td>0.248514</td>\n",
       "      <td>0.166124</td>\n",
       "      <td>10.259016</td>\n",
       "      <td>0.079909</td>\n",
       "      <td>0.075065</td>\n",
       "      <td>0.137016</td>\n",
       "      <td>0.127771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-06 16:45:34.244499968</td>\n",
       "      <td>0.070953</td>\n",
       "      <td>0.307256</td>\n",
       "      <td>0.320381</td>\n",
       "      <td>0.449271</td>\n",
       "      <td>0.115143</td>\n",
       "      <td>9.840561</td>\n",
       "      <td>0.273144</td>\n",
       "      <td>0.274306</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368782</td>\n",
       "      <td>0.172103</td>\n",
       "      <td>0.170834</td>\n",
       "      <td>0.268370</td>\n",
       "      <td>10.027267</td>\n",
       "      <td>0.272663</td>\n",
       "      <td>0.250511</td>\n",
       "      <td>0.327138</td>\n",
       "      <td>0.435102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-06 16:45:35.247000064</td>\n",
       "      <td>0.557709</td>\n",
       "      <td>0.099768</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>0.063887</td>\n",
       "      <td>10.031647</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201086</td>\n",
       "      <td>0.060130</td>\n",
       "      <td>0.115041</td>\n",
       "      <td>0.082050</td>\n",
       "      <td>10.070970</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.013317</td>\n",
       "      <td>0.046099</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       UTC time  x_freq_0.00  x_freq_1.00  x_freq_2.00  \\\n",
       "0 2019-08-06 16:45:31.238000128     0.115494     0.213512     0.125321   \n",
       "1 2019-08-06 16:45:32.240000000     0.189102     0.424405     0.239227   \n",
       "2 2019-08-06 16:45:33.241999872     0.645355     0.403384     0.056071   \n",
       "3 2019-08-06 16:45:34.244499968     0.070953     0.307256     0.320381   \n",
       "4 2019-08-06 16:45:35.247000064     0.557709     0.099768     0.061064   \n",
       "\n",
       "   x_freq_2.99  x_freq_3.99  y_freq_0.00  y_freq_1.00  y_freq_2.00  \\\n",
       "0     0.270987     0.208459     9.829315     0.131838     0.229700   \n",
       "1     0.152204     0.179354     9.860931     0.099776     0.201607   \n",
       "2     0.192648     0.133450    10.186569     0.087794     0.051352   \n",
       "3     0.449271     0.115143     9.840561     0.273144     0.274306   \n",
       "4     0.043690     0.063887    10.031647     0.013636     0.014963   \n",
       "\n",
       "   y_freq_2.99  ...  z_freq_1.00  z_freq_2.00  z_freq_2.99  z_freq_3.99  \\\n",
       "0     0.152028  ...     0.535512     0.386162     0.394200     0.179750   \n",
       "1     0.411713  ...     0.611313     0.339826     0.190252     0.266903   \n",
       "2     0.126917  ...     0.286381     0.355345     0.248514     0.166124   \n",
       "3     0.317647  ...     0.368782     0.172103     0.170834     0.268370   \n",
       "4     0.047105  ...     0.201086     0.060130     0.115041     0.082050   \n",
       "\n",
       "   m_freq_0.00  m_freq_1.00  m_freq_2.00  m_freq_2.99  m_freq_3.99  label  \n",
       "0    10.046286     0.111909     0.256019     0.149530     0.032842      1  \n",
       "1     9.961635     0.054050     0.193307     0.386611     0.373026      1  \n",
       "2    10.259016     0.079909     0.075065     0.137016     0.127771      1  \n",
       "3    10.027267     0.272663     0.250511     0.327138     0.435102      1  \n",
       "4    10.070970     0.026841     0.013317     0.046099     0.006538      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = pd.merge_asof(train_features, train_labels[['UTC time', 'label']], on='UTC time')\n",
    "\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "* Choose a suitable machine learning model for this classification activity. (`RandomForest`, `DecisionTree`, `KNeighbors`, `LogisticRegression` and `SVM` models were considered)\n",
    "    * Evaluate each model using `Cross-validation` on the training data to assess its performance, using metrics like `Accuracy`, `Precision`, `Recall`, and `F1-score`.\n",
    "    * In each `Cross-validation` fold, a `StratifiedKFold` approach will be used to keep classes balanced in each fold, thus avoiding an imbalanced evaluation situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up features, `X_train`, and labels, `Y_train`.\n",
    "X_train = ml_df.iloc[:,1:-1]\n",
    "Y_train = ml_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying some raw ML models to the data and evaluating the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Results:\n",
      "\n",
      "                    accuracy  precision    recall  f1_score    std_f1\n",
      "RandomForest        0.713795   0.724305  0.713795  0.678264  0.036677\n",
      "SVM                 0.671299   0.688468  0.671299  0.670190  0.030678\n",
      "KNeighbors          0.681938   0.669626  0.681938  0.657223  0.028700\n",
      "LogisticRegression  0.625629   0.673138  0.625629  0.634350  0.065348\n",
      "DecisionTree        0.606898   0.621369  0.606898  0.608068  0.040158\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed\n",
    "random_seed = 1\n",
    "\n",
    "# Handling class imbalance by calculating class weights based on the overall distribution\n",
    "classes = np.unique(Y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=Y_train)\n",
    "class_weight_dict = {classes[i]: class_weights[i] for i in range(len(classes))}\n",
    "\n",
    "# Defining the models to compare\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(class_weight=class_weight_dict, random_state=random_seed),\n",
    "    'DecisionTree': DecisionTreeClassifier(class_weight=class_weight_dict, random_state=random_seed),\n",
    "    'KNeighbors': KNeighborsClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=random_seed),\n",
    "    'SVM': SVC(class_weight='balanced', random_state=random_seed)\n",
    "}\n",
    "\n",
    "# Initializing a dictionary to store cross-validation results\n",
    "cv_results = {}\n",
    "\n",
    "# Use StratifiedKFold to handle class imbalance during cross-validation\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_seed) # Creating just 4 folds since the data is less extensive than a regular ML problem.\n",
    "\n",
    "# Defining scoring metrics\n",
    "scoring_metrics = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1_score': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# Evaluating each model using cross-validation\n",
    "for model_name, model in models.items():\n",
    "    # Creating a pipeline to standardize the data and train the model\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()), # Standardizing the features\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    try:\n",
    "        # Performing cross-validation with multiple metrics\n",
    "        cv_results_dict = cross_validate(\n",
    "            pipeline, X_train, Y_train, cv=skf, scoring=scoring_metrics, return_train_score=False\n",
    "        )\n",
    "        # Summarizing the results\n",
    "        summary = {metric: np.mean(cv_results_dict[f'test_{metric}']) for metric in scoring_metrics.keys()}\n",
    "        summary['std_f1'] = np.std(cv_results_dict['test_f1_score'])\n",
    "        cv_results[model_name] = summary\n",
    "    except ValueError as e:\n",
    "        print(f'Error with {model_name}: {e}')\n",
    "\n",
    "# Summarizing the results in a DataFrame\n",
    "cv_results_df = pd.DataFrame(cv_results).T # Transposing for better readability\n",
    "print('\\nCross-Validation Results:\\n')\n",
    "print(cv_results_df.sort_values(by='f1_score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model contains 4 possible classifications, and due to the evident imbalance between classes/labels, the model evaluation focused mainly on the `F1-score` metric.\n",
    "\n",
    "With `F1-score`, and inherently with `Precision` and `Recall`, I'm trying to make sure that the model can recognize each activity as well as possible, instead of just aimlessly try to guess the most likely class, thus maintaining high accuracy.\n",
    "\n",
    "Another important factor for me was, how stable the model is across folds, thus `F1 Score's standard Deviation` was computed.\n",
    "\n",
    "With this, `KNeighbors` was ultimately chosen as the model to use, since it has the best `F1-score`, it's one of the more stable of the models tested and overall holds nice metrics when compared with the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Selected Model\n",
    "\n",
    "- Defined the K-Nearest Neighbors (KNN) classifier as the model to be used.\n",
    "- Created a pipeline that includes:\n",
    "  - `StandardScaler`: Standardizes the features to have zero mean and unit variance.\n",
    "  - `PCA (Principal Component Analysis)`: Reduces the dimensionality of the feature set.\n",
    "  - `KNN Classifier`: Applies the K-Nearest Neighbors algorithm for classification.\n",
    "- Defined a grid of hyperparameters for tuning:\n",
    "  - `knn__n_neighbors`: Number of neighbors to consider (values from 1 to 30).\n",
    "  - `knn__weights`: Weighting function for the neighbors ('uniform' or 'distance').\n",
    "  - `knn__metric`: Distance metric to use ('euclidean', 'manhattan', 'minkowski').\n",
    "  - `pca__n_components`: Number of principal components to keep (ranging from 5 to the maximum number of features).\n",
    "- Cross-Validation Strategy:\n",
    "  - Used StratifiedKFold with 5 splits to maintain the class distribution across training and validation sets, ensuring robustness to class imbalance.\n",
    "  - Applied shuffling and a fixed random seed for reproducibility.\n",
    "- Evaluated models using multiple metrics:\n",
    "  - `accuracy`: The overall accuracy of the model.\n",
    "  - `f1_score`: The weighted F1 score, balancing precision and recall across classes.\n",
    "- Grid Search for Hyperparameter Tuning:\n",
    "  - Employed GridSearchCV to search for the best combination of hyperparameters based on cross-validation results.\n",
    "  - Set the primary refitting metric to `f1_score` to prioritize a balanced performance across all classes.\n",
    "  - Utilized all available CPU cores for efficient computation (`n_jobs=-1`).\n",
    "- Model Training:\n",
    "  - Fitted the grid search pipeline to the training data (`X_train`, `Y_train`).\n",
    "  - Identified and printed the best hyperparameters and their corresponding F1 score.\n",
    "- Using the best estimator from the grid search, predicted the labels of the test set (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_freq_0.00</th>\n",
       "      <th>x_freq_1.00</th>\n",
       "      <th>x_freq_2.00</th>\n",
       "      <th>x_freq_2.99</th>\n",
       "      <th>x_freq_3.99</th>\n",
       "      <th>y_freq_0.00</th>\n",
       "      <th>y_freq_1.00</th>\n",
       "      <th>y_freq_2.00</th>\n",
       "      <th>y_freq_2.99</th>\n",
       "      <th>y_freq_3.99</th>\n",
       "      <th>z_freq_0.00</th>\n",
       "      <th>z_freq_1.00</th>\n",
       "      <th>z_freq_2.00</th>\n",
       "      <th>z_freq_2.99</th>\n",
       "      <th>z_freq_3.99</th>\n",
       "      <th>m_freq_0.00</th>\n",
       "      <th>m_freq_1.00</th>\n",
       "      <th>m_freq_2.00</th>\n",
       "      <th>m_freq_2.99</th>\n",
       "      <th>m_freq_3.99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.053909</td>\n",
       "      <td>0.627749</td>\n",
       "      <td>0.137760</td>\n",
       "      <td>0.982867</td>\n",
       "      <td>0.651082</td>\n",
       "      <td>8.628647</td>\n",
       "      <td>1.805690</td>\n",
       "      <td>1.039583</td>\n",
       "      <td>0.774891</td>\n",
       "      <td>0.936442</td>\n",
       "      <td>1.898743</td>\n",
       "      <td>1.017193</td>\n",
       "      <td>1.117820</td>\n",
       "      <td>0.735290</td>\n",
       "      <td>0.651077</td>\n",
       "      <td>9.853917</td>\n",
       "      <td>1.090203</td>\n",
       "      <td>1.053297</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>1.496570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.556686</td>\n",
       "      <td>0.706339</td>\n",
       "      <td>0.367664</td>\n",
       "      <td>1.251476</td>\n",
       "      <td>1.219198</td>\n",
       "      <td>10.574875</td>\n",
       "      <td>0.912474</td>\n",
       "      <td>2.310563</td>\n",
       "      <td>2.018463</td>\n",
       "      <td>1.671820</td>\n",
       "      <td>1.807266</td>\n",
       "      <td>0.831885</td>\n",
       "      <td>0.942179</td>\n",
       "      <td>0.775075</td>\n",
       "      <td>1.162827</td>\n",
       "      <td>11.585948</td>\n",
       "      <td>0.738994</td>\n",
       "      <td>2.440492</td>\n",
       "      <td>2.442716</td>\n",
       "      <td>2.110637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.583450</td>\n",
       "      <td>0.546440</td>\n",
       "      <td>0.109063</td>\n",
       "      <td>0.476522</td>\n",
       "      <td>0.386264</td>\n",
       "      <td>8.773575</td>\n",
       "      <td>2.108868</td>\n",
       "      <td>1.147501</td>\n",
       "      <td>1.257724</td>\n",
       "      <td>0.329874</td>\n",
       "      <td>1.072083</td>\n",
       "      <td>1.140203</td>\n",
       "      <td>0.744731</td>\n",
       "      <td>0.265736</td>\n",
       "      <td>0.193734</td>\n",
       "      <td>9.662984</td>\n",
       "      <td>1.869028</td>\n",
       "      <td>1.100041</td>\n",
       "      <td>1.298827</td>\n",
       "      <td>0.229161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.676437</td>\n",
       "      <td>0.345553</td>\n",
       "      <td>0.386071</td>\n",
       "      <td>0.382778</td>\n",
       "      <td>0.481016</td>\n",
       "      <td>10.157990</td>\n",
       "      <td>0.813793</td>\n",
       "      <td>0.846929</td>\n",
       "      <td>0.583096</td>\n",
       "      <td>0.912201</td>\n",
       "      <td>1.026321</td>\n",
       "      <td>0.758184</td>\n",
       "      <td>0.448942</td>\n",
       "      <td>0.183436</td>\n",
       "      <td>0.122908</td>\n",
       "      <td>10.785218</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.668781</td>\n",
       "      <td>0.597943</td>\n",
       "      <td>0.929524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.549393</td>\n",
       "      <td>0.239080</td>\n",
       "      <td>0.857956</td>\n",
       "      <td>0.990280</td>\n",
       "      <td>1.272633</td>\n",
       "      <td>8.636169</td>\n",
       "      <td>1.081625</td>\n",
       "      <td>1.442326</td>\n",
       "      <td>0.905758</td>\n",
       "      <td>0.220030</td>\n",
       "      <td>2.582031</td>\n",
       "      <td>2.666340</td>\n",
       "      <td>1.780571</td>\n",
       "      <td>1.431289</td>\n",
       "      <td>1.254697</td>\n",
       "      <td>10.842146</td>\n",
       "      <td>1.617705</td>\n",
       "      <td>2.035780</td>\n",
       "      <td>1.672068</td>\n",
       "      <td>0.508903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_freq_0.00  x_freq_1.00  x_freq_2.00  x_freq_2.99  x_freq_3.99  \\\n",
       "0     2.053909     0.627749     0.137760     0.982867     0.651082   \n",
       "1     3.556686     0.706339     0.367664     1.251476     1.219198   \n",
       "2     2.583450     0.546440     0.109063     0.476522     0.386264   \n",
       "3     2.676437     0.345553     0.386071     0.382778     0.481016   \n",
       "4     2.549393     0.239080     0.857956     0.990280     1.272633   \n",
       "\n",
       "   y_freq_0.00  y_freq_1.00  y_freq_2.00  y_freq_2.99  y_freq_3.99  \\\n",
       "0     8.628647     1.805690     1.039583     0.774891     0.936442   \n",
       "1    10.574875     0.912474     2.310563     2.018463     1.671820   \n",
       "2     8.773575     2.108868     1.147501     1.257724     0.329874   \n",
       "3    10.157990     0.813793     0.846929     0.583096     0.912201   \n",
       "4     8.636169     1.081625     1.442326     0.905758     0.220030   \n",
       "\n",
       "   z_freq_0.00  z_freq_1.00  z_freq_2.00  z_freq_2.99  z_freq_3.99  \\\n",
       "0     1.898743     1.017193     1.117820     0.735290     0.651077   \n",
       "1     1.807266     0.831885     0.942179     0.775075     1.162827   \n",
       "2     1.072083     1.140203     0.744731     0.265736     0.193734   \n",
       "3     1.026321     0.758184     0.448942     0.183436     0.122908   \n",
       "4     2.582031     2.666340     1.780571     1.431289     1.254697   \n",
       "\n",
       "   m_freq_0.00  m_freq_1.00  m_freq_2.00  m_freq_2.99  m_freq_3.99  \n",
       "0     9.853917     1.090203     1.053297     0.100080     1.496570  \n",
       "1    11.585948     0.738994     2.440492     2.442716     2.110637  \n",
       "2     9.662984     1.869028     1.100041     1.298827     0.229161  \n",
       "3    10.785218     0.739819     0.668781     0.597943     0.929524  \n",
       "4    10.842146     1.617705     2.035780     1.672068     0.508903  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up test df's features, `X_test`. Removing the first column 'UTC time' as it isn'd necessary for the model.\n",
    "X_test = test_features.iloc[:, 1:]\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 224 candidates, totalling 896 fits\n",
      "Best Parameters: {'pca__n_components': 20, 'svm__C': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Best F1 Score: 0.7013584581021425\n",
      "Best Accuracy: 0.7272649279341112\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define a pipeline to standardize the data and then apply SVM\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Standardize the features\n",
    "    ('pca', PCA()), # PCA for dimensionality reduction\n",
    "    ('svm', svm_model)\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100], # Regularization parameter\n",
    "    'svm__kernel': ['linear', 'poly', 'rbf', 'sigmoid'], # Kernel types\n",
    "    'svm__gamma': ['scale', 'auto'], # Kernel coefficient\n",
    "    'pca__n_components': [5, 10, 12, 14, 16, 18, 20] # Number of components to keep\n",
    "}\n",
    "\n",
    "# Use StratifiedKFold to handle the imbalance during cross-validation\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# Define scoring metrics to evaluate\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1_score': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit='f1_score', # Refitting based on the F1-score\n",
    "    verbose=2,\n",
    "    n_jobs=-1 # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the Grid Search to the training data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding F1 score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)\n",
    "\n",
    "# Extract and print the best accuracy score\n",
    "best_index = grid_search.best_index_  # Index of the best combination\n",
    "best_accuracy = grid_search.cv_results_['mean_test_accuracy'][best_index]\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "Y_pred = best_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "<h4>Model Performance</h4>\n",
    "\n",
    "- **Cross-Validation**: The KNN model was evaluated using 5-fold cross-validation with stratified splits to handle class imbalance.\n",
    "- **Best Model Parameters**: After hyperparameter tuning, the best model parameters for KNN were identified as:\n",
    "  - `n_neighbors`: 15\n",
    "  - `weights`: distance\n",
    "  - `metric`: euclidean\n",
    "- **Test Set Evaluation**:\n",
    "  - The optimized KNN model was evaluated on the test set, achieving the following metrics:\n",
    "    - **F1 Score**: 0.715\n",
    "    - **Accuracy**: 0.741\n",
    "\n",
    "<h4>Feature Importance</h4>\n",
    "\n",
    "- The extracted frequency-domain features provided significant insights into the underlying patterns of the accelerometer data.\n",
    "- However, not all showed to be relevant since 6 of them were discarded by `PCA`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing prediction results\n",
    "\n",
    "Adding the predicted activities to a new version of the `test_labels.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 4, 4, 2, 4, 3, 2, 4, 4, 3, 3, 2, 2, 4, 4, 2, 3, 3, 4, 4,\n",
       "       2, 2, 4, 4, 4, 3, 4, 2, 4, 3, 2, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 4, 3, 2, 3, 2, 3, 2,\n",
       "       3, 3, 4, 3, 2, 2, 2, 2, 3, 4, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 2, 4,\n",
       "       2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 3, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display raw results.\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated test_labels.csv with predictions saved as 'test_labels_updated.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Ensure Y_pred is the same length as test_labels\n",
    "if len(Y_pred) != len(test_labels):\n",
    "    raise ValueError(\"The length of Y_pred does not match the number of rows in test_labels.\")\n",
    "else:\n",
    "    test_labels['label'] = Y_pred\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "test_labels.to_csv('test_labels_updated.csv', index=False)\n",
    "\n",
    "print(\"Updated test_labels.csv with predictions saved as 'test_labels_updated.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measurement\n",
    "\n",
    "Ends the timer and displays the notebook's total running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping the timer and calculating total runtime\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 7.602516412734985 s\n"
     ]
    }
   ],
   "source": [
    "# Displaying total runtime\n",
    "print(f\"Total runtime: {runtime} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "<h4>Summary of Findings</h4>\n",
    "\n",
    "- The project successfully developed a machine learning model to classify activities based on accelerometer data.\n",
    "- Fourier Transform-based feature extraction proved effective in capturing the relevant patterns in the data.\n",
    "- The K-Nearest Neighbors (KNN) model, after hyperparameter tuning, provided a robust solution to the classification problem.\n",
    "\n",
    "<h4>Insights and Future Work</h4>\n",
    "\n",
    "- Addressing class imbalance through appropriate handling techniques improved the model's ability to generalize across all activity classes.\n",
    "- Future work could explore advanced techniques like Deep Learning or ensemble methods to potentially enhance performance.\n",
    "- Further data collection and additional feature engineering might help in improving the classification accuracy for more complex activities.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
